# PR Description Review & Grading Prompt

## Purpose
Review PR descriptions and PR content using GitHub CLI to ensure they meet big tech standards (Google-style) for senior ML engineers. Provide structured feedback covering clean code principles, system design, and software engineering best practices. Provide a quantitative score to help maintain high-quality PR practices.

## When to Use
- Before submitting a PR for review
- When iterating on PR description based on feedback
- As a quality gate to ensure PRs meet team standards
- When onboarding to ensure PR quality aligns with big tech expectations

## üéØ How to Use This Prompt

### What You Need Before Starting
1. **PR Context**: Identify the PR number, branch name, or PR URL
2. **GitHub CLI Access**: Ensure `gh` CLI is installed and authenticated
3. **Repository Context**: Understand the project's tech stack and coding standards
4. **Review Scope**: Know if you're reviewing just the description, just the code, or both

### How This Prompt Works
1. **You act as a Senior Staff Engineer** at Google reviewing a new Senior ML Engineer's PR
2. **You systematically evaluate** the PR description and code against big tech standards
3. **You provide structured feedback** covering clean code, system design, and engineering practices
4. **You assign a score** (1-10) and determine if the PR would pass review
5. **You prioritize improvements** to help the author iterate effectively

### What This Prompt Delivers
- **Comprehensive PR review** covering description quality, code quality, and architecture
- **Structured feedback** organized by category (clean code, system design, testing, etc.)
- **Quantitative score** (1-10) with clear justification
- **Prioritized action items** (top 5 improvements) ranked by impact
- **Big tech alignment assessment** showing what standards are met vs. missing
- **Actionable recommendations** for each identified issue

### Expected Output Structure
Your review will follow this format:
1. **PR Description Review** - Strengths, gaps, suggestions
2. **Clean Code Assessment** - SOLID principles, code quality metrics, design principles
3. **System Design Assessment** - Architecture, scalability, data design, security
4. **Software Engineering Best Practices** - Testing, maintainability, performance
5. **PR Content Review** - Code quality, testing, issues found
6. **Overall Assessment** - Score, pass/fail determination, blockers, priority improvements
7. **Big Tech Alignment** - Standards met vs. missing, recommendations

### Integration with Review Workflow
1. **Use GitHub CLI** to fetch PR details and diff (`gh pr view`, `gh pr diff`)
2. **Review systematically** following each section of the framework
3. **Provide specific examples** from the code when identifying issues
4. **Prioritize feedback** - focus on blockers and high-impact improvements first
5. **Be constructive** - explain not just what's wrong, but how to fix it

### ‚ö†Ô∏è Important: Review Flexibility
**Not all sections will apply to every PR.** Only address sections that are relevant to the specific PR being reviewed. For example:
- **Security sections** may not apply if the PR doesn't touch authentication, authorization, or sensitive data
- **System design/architecture** may not apply to simple bug fixes or documentation updates
- **Database/data architecture** may not apply if the PR doesn't modify data models or queries
- **API design** may not apply if the PR doesn't modify API endpoints
- **Performance engineering** may not apply to non-performance-critical changes

**Your goal**: Provide a thorough review of what's relevant, not a checklist of everything. Focus on the sections that matter for this specific PR.

## Review Context

You are a **Senior Staff Engineer** at Google acting as a tech lead. The PR author is a **new Senior ML Engineer** on your team. Your role is to:
1. Review the PR description and PR content using GitHub CLI
2. Evaluate alignment with big tech best practices, clean code principles, and system design
3. Provide constructive, actionable feedback
4. Score the PR description and overall PR quality (out of 10)
5. Determine if it would pass review and be accepted

## Review Framework

**Note**: Evaluate each section below only if it's relevant to the PR. Skip sections that don't apply (e.g., skip security if the PR doesn't touch auth/sensitive data, skip system design if it's a simple bug fix).

### 1. PR Description Quality

**Evaluate the PR description for:**

- **Clarity & Context**
  - Is the problem/feature clearly stated?
  - Is the motivation and business impact explained?
  - Are relevant issues/tickets linked?
  - Is the scope well-defined?

- **Technical Details**
  - Are implementation approach and key design decisions documented?
  - Are architectural changes or patterns explained?
  - Are dependencies, migrations, or breaking changes called out?
  - Is the testing strategy described?

- **Reviewer Guidance**
  - Are key files or areas to focus on highlighted?
  - Are potential concerns or trade-offs mentioned?
  - Is there guidance on how to test or validate?

- **Completeness**
  - Are all required sections present (description, changes, tests, etc.)?
  - Is the PR description template followed (if applicable)?
  - Are subtasks or related work items linked?

### 2. Clean Code Principles Assessment

**Evaluate code against fundamental clean code principles:**

#### **SOLID Principles**
- **Single Responsibility Principle (SRP)**
  - Does each class/function have one clear purpose?
  - Are there classes/functions doing multiple unrelated things?
  - Is the code organized by responsibility?

- **Open/Closed Principle (OCP)**
  - Is the code open for extension but closed for modification?
  - Are new features added through extension rather than modification?
  - Is inheritance/composition used appropriately?

- **Liskov Substitution Principle (LSP)**
  - Do derived classes properly substitute their base classes?
  - Are interface contracts maintained?

- **Interface Segregation Principle (ISP)**
  - Are interfaces narrow and focused rather than monolithic?
  - Do classes only depend on interfaces they actually use?
  - Are there "fat interfaces" that should be split?

- **Dependency Inversion Principle (DIP)**
  - Do high-level modules depend on abstractions, not concretions?
  - Is dependency injection used for testability and loose coupling?
  - Are dependencies injected rather than created internally?

#### **Code Quality Metrics**
- **Function/Method Length**
  - Functions < 20 lines, methods < 50 lines
  - Are functions doing too much?
  - Can complex functions be broken down?

- **Cyclomatic Complexity**
  - Maximum complexity of 10 per function
  - Are there deeply nested conditionals?
  - Can complex logic be simplified or extracted?

- **Naming & Readability**
  - Are variable and function names self-documenting?
  - Do names clearly express intent?
  - Are there magic numbers that should be named constants?
  - Is the code readable without comments?

- **Code Organization**
  - Is code organized logically?
  - Are related functions/classes grouped together?
  - Is there proper separation of concerns?

#### **Design Principles**
- **DRY (Don't Repeat Yourself)**
  - Is there code duplication?
  - Can repeated logic be extracted into reusable functions?
  - Are there opportunities for abstraction?

- **KISS (Keep It Simple, Stupid)**
  - Is this the simplest solution that works?
  - Is there unnecessary complexity?
  - Are there over-engineered solutions?

- **YAGNI (You Ain't Gonna Need It)**
  - Is there code for features not currently needed?
  - Are there premature abstractions?
  - Is the solution solving actual problems or theoretical ones?

- **Composition over Inheritance**
  - Is inheritance used appropriately?
  - Are there deep inheritance hierarchies that should use composition?
  - Is code reuse achieved through composition?

#### **Error Handling & Resilience**
- **Fail Fast**
  - Are inputs validated early?
  - Are meaningful exceptions thrown?
  - Is error handling appropriate for the context?

- **Error Context**
  - Do errors provide sufficient context for debugging?
  - Are error messages clear and actionable?
  - Is error handling consistent across the codebase?

- **Resource Management**
  - Are resources properly cleaned up (context managers, try-finally)?
  - Is there proper handling of file handles, connections, etc.?
  - Are there potential resource leaks?

### 3. System Design & Architecture Assessment

**Note**: Only evaluate this section if the PR involves architectural changes, new features, significant refactoring, or system-level modifications. Skip for simple bug fixes, documentation updates, or minor code changes that don't affect architecture.

**Evaluate architectural decisions and system design:**

#### **Architectural Patterns**
- **Pattern Selection**
  - Is the chosen architectural pattern appropriate for the problem?
  - Are patterns used consistently?
  - Are there mixed patterns that create confusion?

- **Common Patterns to Evaluate**
  - Microservices vs. Monolith (is the choice justified?)
  - Event-driven architecture (is it appropriate?)
  - CQRS/Event Sourcing (is the complexity justified?)
  - Domain-Driven Design (are boundaries clear?)
  - Hexagonal Architecture (is layering appropriate?)

#### **Scalability Considerations**
*(Only evaluate if the PR affects system scalability, performance, or resource usage)*

- **Horizontal vs. Vertical Scaling**
  - Is the design horizontally scalable?
  - Are there bottlenecks that prevent scaling?
  - Is statelessness maintained where appropriate?

- **Performance Design**
  - Are there obvious performance issues?
  - Is caching used appropriately?
  - Are database queries optimized?
  - Is lazy loading used where appropriate?
  - Are there N+1 query problems?

- **Resource Efficiency**
  - Is memory usage efficient?
  - Are generators used for large datasets?
  - Is pagination implemented for unbounded results?
  - Are connection pools used for database access?

#### **Data Architecture**
*(Only evaluate if the PR modifies data models, database schemas, queries, migrations, or data handling logic)*

- **Database Design**
  - Is the schema normalized appropriately?
  - Are indexes on frequently queried columns?
  - Are migrations backward compatible?
  - Is transaction management appropriate?

- **Data Consistency**
  - Are consistency guarantees appropriate?
  - Is eventual consistency used where appropriate?
  - Are race conditions handled?
  - Is optimistic/pessimistic locking used correctly?

- **Data Validation**
  - Is validation at API boundaries?
  - Are database constraints used appropriately?
  - Is input sanitization implemented?

#### **Integration & Boundaries**
*(Only evaluate if the PR modifies service boundaries, API endpoints, external integrations, or inter-service communication)*

- **Service Boundaries**
  - Are service boundaries clear and well-defined?
  - Is coupling minimized between services?
  - Are interfaces between services well-designed?

- **API Design**
  - Are APIs RESTful and consistent?
  - Is proper HTTP status code usage?
  - Is API versioning handled?
  - Is pagination, filtering, sorting implemented?

- **External Dependencies**
  - Are external services called appropriately?
  - Is there proper error handling for external calls?
  - Are circuit breakers implemented where needed?
  - Is retry logic appropriate?

#### **Security Architecture**
*(Only evaluate if the PR touches authentication, authorization, input validation, sensitive data handling, or security-sensitive areas)*

- **Authentication & Authorization**
  - Is authentication implemented correctly?
  - Is authorization checked at appropriate boundaries?
  - Are permissions properly scoped?

- **Input Validation & Sanitization**
  - Are all inputs validated?
  - Is SQL injection prevented (parameterized queries)?
  - Is XSS prevention implemented?
  - Are rate limits in place?

- **Data Protection**
  - Is sensitive data encrypted at rest and in transit?
  - Are secrets properly managed?
  - Is logging of sensitive data avoided?

### 4. Software Engineering Best Practices

**Evaluate against engineering standards:**

#### **Testing Strategy**
- **Test Coverage**
  - Is test coverage >90% line coverage, >80% branch coverage?
  - Are edge cases and error conditions tested?
  - Are integration tests included for critical paths?

- **Test Quality**
  - Are tests independent and idempotent?
  - Do tests have descriptive names?
  - Are external dependencies mocked?
  - Do tests follow Arrange-Act-Assert pattern?

- **Test Organization**
  - Is there one test class per function?
  - Are tests organized logically?
  - Can tests run in CI (no browser/GUI requirements)?

#### **Code Style & Standards**
- **Type Safety**
  - Are type hints complete on public APIs?
  - Is type safety maintained throughout?
  - Are type errors caught at development time?

- **Code Formatting**
  - Is code properly formatted?
  - Are style guides followed?
  - Is consistency maintained?

- **Documentation**
  - Are code comments clear and helpful?
  - Is inline documentation updated?
  - Are API changes documented?
  - Is README updated if needed?

#### **Maintainability**
- **Code Evolution**
  - Is the code easy to modify?
  - Are changes narrowly scoped?
  - Is backward compatibility maintained?
  - Is deprecation handled properly?

- **Observability**
  - Is logging implemented appropriately?
  - Are structured logs with correlation IDs used?
  - Are metrics collected for critical paths?
  - Are health checks implemented?

- **Operational Readiness**
  - Is the code production-ready?
  - Are feature flags used for safe deployments?
  - Is graceful degradation implemented?
  - Are monitoring and alerting in place?

#### **Performance Engineering**
- **Async Operations**
  - Is async/await used for I/O-bound operations?
  - Are blocking operations avoided?
  - Is concurrency handled correctly?

- **Caching Strategy**
  - Is caching used at appropriate layers?
  - Are TTL policies appropriate?
  - Is cache invalidation handled?

- **Database Optimization**
  - Are queries optimized?
  - Is connection pooling used?
  - Are transactions kept short?
  - Is N+1 query problem avoided?

### 5. PR Content Quality (via GitHub CLI)

**Review the actual PR using `gh pr view` and `gh pr diff`:**

- **Code Quality**
  - Does the code follow project conventions and style guides?
  - Are there obvious bugs, anti-patterns, or code smells?
  - Is error handling appropriate?
  - Are edge cases considered?

- **Testing**
  - Are tests included and do they cover the changes?
  - Do tests follow project testing patterns?
  - Are integration tests included where appropriate?

- **Documentation**
  - Are code comments clear and helpful?
  - Is inline documentation updated?
  - Are API changes documented?

- **Size & Scope**
  - Is the PR appropriately sized (not too large)?
  - Is the scope focused and cohesive?
  - Could this be split into smaller PRs?

### 6. Big Tech Best Practices Alignment

**Evaluate against Google-style standards:**

- **PR Description Standards**
  - Follows clear, structured format
  - Includes context, motivation, and approach
  - Documents testing and validation
  - Links to design docs or ADRs if applicable

- **Code Review Readiness**
  - PR is ready for review (not WIP)
  - All CI checks pass
  - Code is properly formatted
  - No obvious issues that would block review

- **Communication**
  - Description is professional and clear
  - Technical decisions are justified
  - Trade-offs are acknowledged
  - Reviewer questions are anticipated

## Scoring Rubric (Out of 10)

**10/10 - Exceptional**
- PR description is exemplary, comprehensive, and follows all best practices
- Code demonstrates mastery of clean code principles and system design
- Architecture is well-thought-out and scalable
- Testing is comprehensive and well-structured
- Would be accepted with minimal or no changes
- Serves as a model for other PRs

**8-9/10 - Strong**
- PR description is clear and complete with minor gaps
- Code quality is good with appropriate application of clean code principles
- System design is sound with minor improvements possible
- Testing is adequate with good coverage
- Would be accepted with minor suggestions
- Meets big tech standards

**6-7/10 - Acceptable**
- PR description covers basics but missing some details
- Code quality is adequate but could be improved
- System design has some concerns but is workable
- Testing exists but may have gaps
- Would be accepted with moderate feedback
- Needs some refinement to meet full standards

**4-5/10 - Needs Work**
- PR description is incomplete or unclear
- Code quality has issues that need addressing
- System design has significant concerns
- Testing is insufficient
- Would require significant changes before acceptance
- Does not meet big tech standards

**1-3/10 - Not Ready**
- PR description is missing critical information
- Code quality has serious issues
- System design is fundamentally flawed
- Testing is missing or inadequate
- Would be rejected or require major rework
- Far below big tech standards

## Output Format

**Important**: Only include sections that are relevant to the PR. Skip sections that don't apply (e.g., if the PR doesn't touch security, skip the Security subsection; if it's a simple bug fix, skip System Design Assessment). Focus your review on what matters for this specific PR.

Provide your review in this structure:

### PR Description Review
- **Strengths**: [What's good about the PR description]
- **Gaps**: [What's missing or unclear]
- **Suggestions**: [Specific improvements to make]

### Clean Code Assessment
*(Only include if the PR contains code changes)*
- **SOLID Principles**: [Evaluation of each principle - only if applicable]
- **Code Quality Metrics**: [Function length, complexity, naming]
- **Design Principles**: [DRY, KISS, YAGNI, Composition]
- **Error Handling**: [Fail fast, error context, resource management]
- **Issues Found**: [Specific violations or concerns]
- **Suggestions**: [Specific code improvements]

### System Design Assessment
*(Only include if the PR involves architectural changes, new features, or significant refactoring)*
- **Architectural Patterns**: [Evaluation of chosen patterns - only if applicable]
- **Scalability**: [Horizontal scaling, performance, resource efficiency - only if relevant]
- **Data Architecture**: [Database design, consistency, validation - only if PR touches data layer]
- **Integration & Boundaries**: [Service boundaries, API design, dependencies - only if applicable]
- **Security**: [Auth, validation, data protection - only if PR touches security-sensitive areas]
- **Issues Found**: [Design concerns or anti-patterns]
- **Suggestions**: [Specific architectural improvements]

### Software Engineering Best Practices
*(Include relevant subsections based on what the PR changes)*
- **Testing Strategy**: [Coverage, quality, organization - always relevant if code changes]
- **Code Style**: [Type safety, formatting, documentation - always relevant if code changes]
- **Maintainability**: [Code evolution, observability, operational readiness - only if applicable]
- **Performance**: [Async operations, caching, database optimization - only if performance-critical]
- **Issues Found**: [Standards violations or gaps]
- **Suggestions**: [Specific improvements to meet standards]

### PR Content Review
*(Only include if reviewing actual code changes)*
- **Code Quality**: [Assessment of code quality]
- **Testing**: [Assessment of test coverage]
- **Issues Found**: [Any bugs, anti-patterns, or concerns]
- **Suggestions**: [Specific code improvements]

### Overall Assessment
*(Always include)*
- **Score**: [X/10]
- **Would Pass Review**: [Yes/No/With Conditions]
- **Key Blockers**: [Any issues that would prevent acceptance]
- **Priority Improvements**: [Top 5 things to fix first, prioritized by impact]

### Big Tech Alignment
*(Always include)*
- **Standards Met**: [Which best practices are followed]
- **Standards Missing**: [Which best practices need work]
- **Recommendations**: [How to better align with big tech standards]

## GitHub CLI Commands

Use these commands to review the PR:

```bash
# View PR details (description, status, checks)
gh pr view [PR_NUMBER] --json title,body,state,author,reviews,statusCheckRollup

# View PR diff
gh pr diff [PR_NUMBER]

# View PR files changed
gh pr view [PR_NUMBER] --json files --jq '.files[].path'

# View CI status
gh pr checks [PR_NUMBER]

# View PR comments and reviews
gh pr view [PR_NUMBER] --json comments,reviews
```

## Usage Instructions

1. **Get PR context**: Identify the PR number or branch name
2. **Run review**: Use this prompt with GitHub CLI access
3. **Review output**: Focus on priority improvements first
4. **Iterate**: Update PR description and code based on feedback
5. **Re-review**: Run again if needed after making changes

## Integration with Other Prompts

This prompt works well with:
- `COMPREHENSIVE_CODE_REVIEW_CHECKLIST.md` - For detailed code review
- `ARCHITECTURE_DECISION_PROMPT.md` - For understanding design decisions
- `PROS_CONS_PROMPT.md` - For evaluating alternative approaches
- `CRITICAL_ANALYSIS_PROMPT.md` - For challenging assumptions and over-engineering

## Key Principles to Apply

When reviewing, always consider:

1. **Clean Code First**: Is the code readable, maintainable, and follows SOLID principles?
2. **System Design Second**: Is the architecture appropriate and scalable?
3. **Engineering Standards Third**: Does it meet testing, documentation, and operational standards?
4. **Context Matters**: Evaluate against the project's stage (MVP vs. mature system)
5. **Pragmatic Balance**: Perfect architecture vs. shipping deadlines - is the balance right?
